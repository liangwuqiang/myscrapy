<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>python Selector</h1></center></p>
            <div class="cont">
<h1>python Selector</h1>
<p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">基本介绍</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><strong>实例化：</strong></p><p><strong><br/></strong></p><p>CrawlSpider example</p><p> </p><p>Let’s now take a look at an example CrawlSpider with rules:</p><p> </p><p>import scrapy</p><p> </p><p>from scrapy.spiders import CrawlSpider, Rule from scrapy.linkextractors import LinkExtractor</p><p> </p><p>class</p><p>MySpider(CrawlSpider):</p><p>name='example.com'</p><p>allowed_domains = ['example.com']</p><p>start_urls = ['http://www.example.com']</p><p>rules = (</p><p> </p><p>• Extract links matching 'category.php' (but not matching 'subsection.php')</p><p> </p><p>• and follow links from them (since no callback means follow=True by default).</p><p> </p><p>Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))),</p><p> </p><p>• Extract links matching 'item.php' and parse them with the spider's method parse_item</p><p> </p><p>Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'),</p><p> </p><p>)</p><p> </p><p>def parse_item(self, response):</p><p> </p><p>self.logger.info('Hi, this is an item page! %s', response.url) item = scrapy.Item()</p><p> </p><p>item['id'] = response.xpath('//td[@id="item_id"]/text()').re(r'ID: (\d+)') item['name'] = response.xpath('//td[@id="item_name"]/text()').extract() item['description'] = response.xpath('//td[@id="item_description"]/text()').extract() return item</p><p> </p><p> </p><p>XMLFeedSpider example</p><p> </p><p>These spiders are pretty easy to use, let’s have a look at one example:</p><p>from scrapy.spiders import XMLFeedSpider from myproject.items import TestItem</p><p> </p><p>class MySpider(XMLFeedSpider):</p><p>name = 'example.com'</p><p>allowed_domains = ['example.com']</p><p> </p><p>start_urls = ['http://www.example.com/feed.xml']</p><p> </p><p>iterator = 'iternodes' # This is actually unnecessary, since it's the default value itertag = 'item'</p><p>def parse_node(self, response, node):</p><p> </p><p>self.logger.info('Hi, this is a &lt;%s&gt; node!: %s', self.itertag, ''.join(node.extract()))</p><p>item = TestItem()</p><p>item['id'] = node.xpath('@id').extract()</p><p>item['name'] = node.xpath('name').extract()</p><p>item['description'] = node.xpath('description').extract()</p><p>return item</p><p> </p><p><strong>常用方法：</strong></p><p><strong><br/></strong></p><p>1）xpath</p><p>  2）css</p><p>  3）re</p><p>  4）extract</p><p> </p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">应用实例，以下面的代码为例，抽取其中的数据</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p>Here’s its HTML code: </p><p><br/></p><pre class="brush:html;toolbar:false">&lt;html&gt;
&lt;head&gt; 
&lt;base href='http://example.com/' /&gt; &lt;title&gt;Example website&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div id='images'&gt;
&lt;a href='image1.html'&gt;Name: My image 1 &lt;br /&gt;&lt;img src='image1_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image2.html'&gt;Name: My image 2 &lt;br /&gt;&lt;img src='image2_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image3.html'&gt;Name: My image 3 &lt;br /&gt;&lt;img src='image3_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image4.html'&gt;Name: My image 4 &lt;br /&gt;&lt;img src='image4_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image5.html'&gt;Name: My image 5 &lt;br /&gt;&lt;img src='image5_thumb.jpg' /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;</pre><p> </p><p><strong>操作流程</strong>：</p><p><br/></p><p>First, let’s open the shell:</p><p> </p><p>scrapy shell http://doc.scrapy.org/en/latest/_static/selectors-sample1.html</p><p> </p><p>Then, after the shell loads, you’ll have the response available as response shell variable, and its attached selector in response.selector attribute.</p><p> </p><p>Since we’re dealing with HTML, the selector will automatically use an HTML parser.</p><p> </p><p>So, by looking at the HTML code of that page, let’s construct an XPath for selecting the text inside the title tag:</p><p> </p><p>&gt;&gt;&gt; response.selector.xpath('//title/text()') [&lt;Selector (text) xpath=//title/text()&gt;]</p><p> </p><p>Querying responses using XPath and CSS is so common that responses include two convenience shortcuts: response.xpath() and response.css():</p><p><br/></p><p><strong>抽取第一个文本内容：</strong></p><p><strong><br/></strong></p><p>If you want to extract only first matched element, you can call the selector .extract_first()</p><p> </p><p>&gt;&gt;&gt; response.xpath('//div[@id="images"]/a/text()').extract_first() u'Name: My image 1 '</p><p> </p><p>It returns None if no element was found:</p><p> </p><p>&gt;&gt;&gt; response.xpath('//div/[id="not-exists"]/text()').extract_first() is None True</p><p><br/></p><p><br/></p><p style="margin-top: 0px; margin-bottom: 0px; padding: 0px; border: 0px; outline: 0px; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;"><span style="margin: 0px; padding: 0px; border: 0px; outline: 0px; font-weight: 700; line-height: 20px; background: rgb(255, 255, 255);"><span style="margin: 0px; padding: 0px; border: 0px; outline: 0px; color: rgb(192, 0, 0); background: transparent;">【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></span></p><p>
</p></p></div>
        </body></html>