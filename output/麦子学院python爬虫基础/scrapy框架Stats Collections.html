<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>scrapy框架Stats Collections</h1></center></p>
            <div class="cont">
<h1>scrapy框架Stats Collections</h1>
<p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">基本操作</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p>Access the stats collector through the stats attribute. Here is an example of an extension that access stats:</p><p>class ExtensionThatAccessStats(object):</p><p> </p><p>def __init__(self, stats):</p><p> self.stats = stats</p><p>@classmethod</p><p>def from_crawler(cls, crawler):</p><p> return cls(crawler.stats)</p><p> </p><p><strong>Set stat value:</strong></p><p><strong><br/></strong></p><p>stats.set_value('hostname', socket.gethostname())</p><p><br/></p><p><strong>Increment stat value:</strong></p><p><strong><br/></strong></p><p>stats.inc_value('pages_crawled')</p><p><br/></p><p><strong>Set stat value only if greater than previous:</strong></p><p><strong><br/></strong></p><p>stats.max_value('max_items_scraped', value)</p><p><br/></p><p><strong>Set stat value only if lower than previous:</strong></p><p><strong><br/></strong></p><p>stats.min_value('min_free_memory_percent', value)</p><p><br/></p><p><strong>Get stat value:</strong></p><p><strong><br/></strong></p><p>&gt;&gt;&gt;stats.get_value('pages_crawled')</p><p> 8</p><p><br/></p><p><strong>Get all stats:</strong></p><p><strong><br/></strong></p><p>&gt;&gt;&gt; stats.get_stats()</p><p>{'pages_crawled': 1238, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</p><p><br/></p><hr/><h3><span style="color: rgb(94, 207, 186);">内置可用收集器</span><br/></h3><p><br/></p><p><strong>class scrapy.statscollectors.MemoryStatsCollector</strong></p><p><strong><br/></strong></p><p>A simple stats collector that keeps the stats of the last scraping run (for each spider) in memory, after they’re closed. The stats can be accessed through the spider_stats attribute, which is a dict keyed by spider domain name. </p><p>This is the default Stats Collector used in Scrapy.</p><p><br/></p><p><strong>spider_stats</strong></p><p> </p><p>A dict of dicts (keyed by spider name) containing the stats of the last scraping run for each spider.</p><p><br/></p><p><strong>class scrapy.statscollectors.DummyStatsCollector</strong></p><p> </p><p>A Stats collector which does nothing but is very efficient (because it does nothing). This stats collector can be set via the STATS_CLASS setting, to disable stats collect in order to improve performance. However, the performance penalty of stats collection is usually marginal compared to other Scrapy workload like parsing pages.</p><p><br/></p><p><br/></p><p><span style='color: rgb(192, 0, 0); font-family: "microsoft yahei"; font-weight: bold; line-height: 20px; background-color: rgb(255, 255, 255);'>【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></p><p>
</p></p></div>
        </body></html>