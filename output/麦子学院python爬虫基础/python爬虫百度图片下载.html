<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>python爬虫百度图片下载</h1></center></p>
            <div class="cont">
<h1>python爬虫百度图片下载</h1>
<p><p><br/></p><hr/><h3><span style="color: rgb(94, 207, 186);">从百度下载图片</span></h3><p><br/></p><p><img alt="picture1.png" height="455" src="images/c097405e95a79e2f2031daa20fb58787.png" style="width: 702px; height: 455px;" title="txBMYX1SqhiOMD24YW.png" width="702"/></p><p><br/></p><p>这些图片到底在网页的什么位置呢？怎么把它抓下来呢？一样的，我们打开开发者工具，选中这些图片，这个图片就在这里。</p><p><br/></p><p><img alt="picture2.png" src="images/85320aade00498eb7ec559246f646565.png" title="yb7va9WYQb1PI3uacR.png"/></p><p><br/></p><p>我们看下这个url在网页里面有没有，我们去找网页的原始数据，发现找不到。</p><p><br/></p><p><img alt="picture3.png" height="433" src="images/d8ba000f8654f5c5c628ede0dab31643.png" style="width: 687px; height: 433px;" title="aQBcEVhbWOokCeqlzI.png" width="687"/></p><p><br/></p><p>这是怎么回事呢？因为这个网页图片实际上是一个动态的demo，它的网页原始数据其实是没有这个图片的，通过运行JavaScript，把这个图片数据把它插入到网页的html标签里面，那这样造成的结果是，我们在开发者工具中虽然能看到这个html标签，但实际上，当我们在看网页的原始数据的时候，其实是没有这个标签的，它只在运行时加载和渲染，那这个时候怎么办呢？怎么把这个图片给下载下来呢？这里面我们就换一个思路，我们就来抓包。</p><p><br/></p><p>可以看到我们这里一共是发了60个http请求，我们只能一个个往下看去寻找我们感兴趣的。</p><p><br/></p><p><img alt="picture4.png" height="427" src="images/68d62f12caac7d5e24b8dd966e5c23f3.png" style="width: 726px; height: 427px;" title="eJRnnf6SWwfr3kTwvX.png" width="726"/></p><p><br/></p><p>第一个请求是网页的原始数据</p><p><br/></p><p><img alt="picture5.png" src="images/493f62287972dc3dc8795ca0940c828f.png" title="gH7VuqdPS5My3irltk.png"/></p><p><br/></p><p>这个是真正下载图片的请求，我们可以看到这个图片的url，那也就是说，这个请求里面一定有一个途径能够获取到这个url，这样它才能去从这个url去下载图片。</p><p><br/></p><p><img alt="picture6.png" src="images/edb4a74f97bff0e313c3b026e015a68e.png" title="HDK1VwPinEE0dgjP1R.png"/></p><p><br/></p><p>实际上在网页数据里面，这个url是找不到的，那也就是说，我们可以推理的出来，这个url一定是之前的某些请求里面获取过来的。</p><p>我们直接往下找，最终我们找到了这样的请求，我们可以看到这个请求的应答它是个json数据，我们猜想这里面的数据意思是国家地理的图片是163张</p><p><br/></p><p><img alt="picture7.png" src="images/61b4dd7bcc5616a28f2b30efa2ab1db0.png" title="llEDe4Xz3KJ2ABwLNQ.png"/></p><p><br/></p><p>我们再看里面的数据，这个数据是从0到18，而且这个18数据是空的，所以0到17刚好是18个</p><p><br/></p><p><img alt="picture8.png" src="images/dadbe9a0e3663a74e4dc73eb145fa153.png" title="EsSVNElUMBpEroTrb2.png"/></p><p><br/></p><p>我们看第一个图片，我们关心的是这里面的downloadurl，我们把这个内容拷出来，在浏览器里面看一下。</p><p><br/></p><p><img alt="picture9.png" src="images/5d1a727c81f7dd80194c81e962d47f51.png" title="uKQtd0fQ6vcf1HyUau.png"/></p><p><br/></p><p>我们可以看到，这个确实是一张图片，这样实际上我们就找到了这个数据。</p><p><br/></p><p><img alt="picture10.png" height="440" src="images/15296d9589baa22daaeac9e3c9c38023.png" style="width: 733px; height: 440px;" title="ofdegpExr1lcT82jbK.png" width="733"/></p><p><br/></p><p>我们再看一下这个请求里的数据，这个是请求的网址。</p><p><br/></p><p><img alt="picture11.png" src="images/41d32e3187881aca305fa63cf99e8edd.png" title="Or5IW7gC2dtcD1rzhf.png"/></p><p><br/></p><p>这个是请求的参数。</p><p><br/></p><p><img alt="picture12.png" src="images/987c0d6faeb5cb7e60f640937a109587.png" title="ELkprPtTEsutqexfiO.png"/></p><p><br/></p><p>这个是请求的cookie，这个cookie会不会起作用呢？也就是说如果不带cookie它能不能正常的返回cookie。</p><p><br/></p><p><img alt="picture13.png" src="images/748740a02624d3104dc26318db56fee0.png" title="U6gRhw7c4RQcaR9xzQ.png"/></p><p><br/></p><p>我们先从简单的来试，我们先把请求里面的参数原封不动的给它拷过去，然后向请求的url发送一个请求，我们看看能不能得到这个数据，能够得到数据就完成了。</p><p><br/></p><p><img alt="picture14.png" src="images/2b54eac47152a639dccb210e53dd5666.png" title="BsOmCU8mIQEOltkZAV.png"/></p><p><br/></p><p>假设不能得到数据，那我们就要分析整个数据的headers，整个数据的headers里面最关键的就是这个cookie，也就是说，有可能百度的图片它会根据cookie去健全，也就是说，只有带了这些cookie的才能返回这个数据。</p><p><br/></p><p><img alt="picture15.png" src="images/98c3ebfb6e1378c64fd0ab115b1affaa.png" title="psvAOy6NQtb29knhmc.png"/></p><p><br/></p><p>我们先试简单的，我们看看用代码怎么实现这个过程。</p><p><br/></p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p><br/></p><p>def download_wallpaper():</p><p>    # 数据分析</p><p>    url = 'http://image.baidu.com/data/imgs'   //这个url就是我们刚刚分析的下载json数据的url</p><p>    params = {   //下载的参数</p><p>        'pn': 41,</p><p>        'rn': 100,</p><p>        'col': '壁纸',</p><p>        'tag': '国家地理',</p><p>        'tag3': '',</p><p>        'width': 1600,</p><p>        'height': 900,</p><p>        'ic': 0,</p><p>        'ie': 'utf8',</p><p>        'oe': 'utf-8',</p><p>        'image_id': '',</p><p>        'fr': 'channel',</p><p>        'p': 'channel',</p><p>        'from': 1,</p><p>        'app': 'img.browse.channel.wallpaper',</p><p>        't': '0.016929891658946872'</p><p>    }</p><p>    s = requests.get(url, params=params)    //获取应答</p><p>print(r.json())   //转换成json</p><p><br/></p><p>if __name__ == '__main__':</p><p>    download_wallpaper()</p><p><br/></p><p>运行结果。</p><p><br/></p><p><img alt="picture16.png" src="images/34516f9406ac878b82ca532a05bac1a8.png" title="E4al7srtOLronatHJM.png"/></p><p><br/></p><p>我们看看有没有downloadurl</p><p><br/></p><p><img alt="picture17.png" src="images/6ca692bd36943348d1b48e3ed09b27d8.png" title="FQMVCsrGBj7a2KiIdZ.png"/></p><p><br/></p><p>我们把这个downloadurl打开，看看是什么，可以看到，这个确实是一张图片，看来这个方式是可行的。不需要去处理cookie的信息，就可以把这个json给它下下来。</p><p><br/></p><p><img alt="picture18.png" height="373" src="images/3596e2a3f42582d587a4f90a86ed2350.png" style="width: 647px; height: 373px;" title="reVu4tF6HuIyUojY0h.png" width="647"/></p><p><br/></p><p>那接下来的爬虫实际上就简单了，我们把json里面的宿主给它下载下来就好。</p><p><br/></p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p>import urllib</p><p>import os</p><p><br/></p><p>def _download_image(url, folder=’image’):   //参数为url，和目录</p><p>print('downloading %s' % url)</p><p>   def_fname(s):</p><p>return os.path.join(folder,os.path.split(url)[1])</p><p>    urllib.urlretrieve(url, _fname())    //第一个参数为url，第二个为文件名</p><p><br/></p><p>def download_wallpaper():</p><p>    # 数据分析</p><p>    url = 'http://image.baidu.com/data/imgs'   //这个url就是我们刚刚分析的下载json数据的url</p><p>    params = {   //下载的参数</p><p>        'pn': 41,</p><p>        'rn': 100,</p><p>        'col': '壁纸',</p><p>        'tag': '国家地理',</p><p>        'tag3': '',</p><p>        'width': 1600,</p><p>        'height': 900,</p><p>        'ic': 0,</p><p>        'ie': 'utf8',</p><p>        'oe': 'utf-8',</p><p>        'image_id': '',</p><p>        'fr': 'channel',</p><p>        'p': 'channel',</p><p>        'from': 1,</p><p>        'app': 'img.browse.channel.wallpaper',</p><p>        't': '0.016929891658946872'</p><p>    }</p><p>    s = requests.get(url, params=params)    //获取应答</p><p> imgs = s.json()['imgs']    //图片列表给它去出来</p><p>    print('totally %d images ' % len(imgs))   //打印出总共有多少张图片</p><p>    for i in imgs:</p><p>            _download_image(i['downloadUrl']')</p><p><br/></p><p>if __name__ == '__main__':</p><p>    download_wallpaper()</p><p><br/></p><p>运行结果，我们看它有报错，报错是说没有这个文件夹。</p><p><br/></p><p><img alt="picture19.png" src="images/3f8095937ad3a09832b56531b782e912.png" title="rCU2PsyWTNpNBscnPW.png"/></p><p><br/></p><p>如果这个文件夹不存在，我们需要去创建它。</p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p>import urllib</p><p>import os</p><p><br/></p><p>def _download_image(url, folder=’image’):   //参数为url，和目录</p><p>   if not os.path.isdir(folder):   //如果这个文件夹不存在，我们需要去创建它</p><p>        os.mkdir(folder)</p><p><br/></p><p>print('downloading %s' % url)</p><p>   def_fname(s):</p><p>return os.path.join(folder,os.path.split(url)[1])</p><p>    urllib.urlretrieve(url, _fname())    //第一个参数为url，第二个为文件名</p><p><br/></p><p>def download_wallpaper():</p><p>    # 数据分析</p><p>    url = 'http://image.baidu.com/data/imgs'   //这个url就是我们刚刚分析的下载json数据的url</p><p>    params = {   //下载的参数</p><p>        'pn': 41,</p><p>        'rn': 100,</p><p>        'col': '壁纸',</p><p>        'tag': '国家地理',</p><p>        'tag3': '',</p><p>        'width': 1600,</p><p>        'height': 900,</p><p>        'ic': 0,</p><p>        'ie': 'utf8',</p><p>        'oe': 'utf-8',</p><p>        'image_id': '',</p><p>        'fr': 'channel',</p><p>        'p': 'channel',</p><p>        'from': 1,</p><p>        'app': 'img.browse.channel.wallpaper',</p><p>        't': '0.016929891658946872'</p><p>    }</p><p>    s = requests.get(url, params=params)    //获取应答</p><p> imgs = s.json()['imgs']    //图片列表给它去出来</p><p>    print('totally %d images ' % len(imgs))   //打印出总共有多少张图片</p><p>    for i in imgs:</p><p>            _download_image(i['downloadUrl']')</p><p><br/></p><p>if __name__ == '__main__':</p><p>    download_wallpaper()</p><p><br/></p><p>运行结果，我们可以看到总共有21张图片，但是我们最后又报错了，它说我没有downloadUrl，这是为什么呢？因为我们在数据里面，它最后是空的，所以我们这里面需要把空的给它过滤掉。</p><p><br/></p><p><img alt="picture20.png" src="images/86bb6b48927397321ab3bf234de29740.png" title="IvExBkCq1IAGpUI4kp.png"/></p><p><br/></p><p>修改代码</p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p>import urllib</p><p>import os</p><p><br/></p><p>def _download_image(url, folder=’image’):   //参数为url，和目录</p><p>   if not os.path.isdir(folder):   //如果这个文件夹不存在，我们需要去创建它</p><p>        os.mkdir(folder)</p><p><br/></p><p>print('downloading %s' % url)</p><p>   def_fname(s):</p><p>return os.path.join(folder,os.path.split(url)[1])</p><p>    urllib.urlretrieve(url, _fname())    //第一个参数为url，第二个为文件名</p><p><br/></p><p>def download_wallpaper():</p><p>    # 数据分析</p><p>    url = 'http://image.baidu.com/data/imgs'   //这个url就是我们刚刚分析的下载json数据的url</p><p>    params = {   //下载的参数</p><p>        'pn': 41,</p><p>        'rn': 100,</p><p>        'col': '壁纸',</p><p>        'tag': '国家地理',</p><p>        'tag3': '',</p><p>        'width': 1600,</p><p>        'height': 900,</p><p>        'ic': 0,</p><p>        'ie': 'utf8',</p><p>        'oe': 'utf-8',</p><p>        'image_id': '',</p><p>        'fr': 'channel',</p><p>        'p': 'channel',</p><p>        'from': 1,</p><p>        'app': 'img.browse.channel.wallpaper',</p><p>        't': '0.016929891658946872'</p><p>    }</p><p>    s = requests.get(url, params=params)    //获取应答</p><p> imgs = s.json()['imgs']    //图片列表给它去出来</p><p>    print('totally %d images ' % len(imgs))   //打印出总共有多少张图片</p><p>    for i in imgs:</p><p>for i in imgs:</p><p>        if 'downloadUrl' in i:</p><p>            _download_image(i['downloadUrl']')</p><p><br/></p><p>if __name__ == '__main__':</p><p>    download_wallpaper()</p><p><br/></p><p>运行结果。</p><p><br/></p><p><img alt="picture21.png" src="images/eb05fce8eb5b2d2c01758d7b4e6e6431.png" title="P8MYQxdl2N9hrONAhz.png"/></p><p><br/></p><p>我们可以看一下这个imgs目录，这是我们下载下来的图片。</p><p><br/></p><p><img alt="picture22.png" src="images/b38b2666e129e0b7097cc5c950f68371.png" title="ugecJZtrJjpWoLMoTx.png"/></p><p><br/></p><p><br/></p><p><br/></p><p><span style="color: rgb(192, 0, 0);">【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></p><p><br/></p><p>
</p></p></div>
        </body></html>