<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>爬虫之download_poem</h1></center></p>
            <div class="cont">
<h1>爬虫之download_poem</h1>
<p><p><br/></p><hr/><h3><span style="color: rgb(94, 207, 186);">download_poem函数</span></h3><p><br/></p><p>现在我们要爬取唐诗三百首的完整内容，我们来看这个函数download_poem</p><p><br/></p><p>def download_poem(poem):</p><p>r = requests.get('http://www.gushiwen.org' + poem['url'])   //唐诗所在的url</p><p>r = request.get(url)  //下载唐诗的网页</p><p>parser = PoemContentParser(r.content)   //构造一个解析器，把这个内容传进去</p><p>return parser.content   //返回唐诗的内容</p><p>    </p><p>查看怎么解析唐诗的内容，这个时候我们需要分析唐诗网页的数据：</p><p><br/></p><p>打开行宫这首诗，使用chrome开发者工具，选中这首诗的内容，定位到诗词所在的html标签，经过内容我们可以看到，唐诗的内容在p align=”center”这样的一个标签里面。也就是这个网页只有一个p align=”center”这样的一个标签，这个是通过归纳总结出来的，也就是这个规则要通过具体的网页去分析的。</p><p><br/></p><p><img alt="grab1.png" src="images/7b643b1333b5b4731a9d45162b66c0db.png" title="DeWxFFePFHtAdkx32P.png"/></p><p><br/></p><p>打开另一首诗，这个里面有四行的内容，所以我们现在的规则应该比较清楚，就是去找到p align=”center”这样的一个标签，然后把这里面的内容给它保存下来，这个内容因为里面插了&lt;br&gt;，所以这个是4行，所以我们的唐诗内容应该是一个列表。</p><p><br/></p><p><img alt="grab2.png" src="images/6d9d2d738a3bce48dc7fa01fc9bcf043.png" title="EkSuLOI1lEYUoKZkIR.png"/></p><p><br/></p><p>通过以上的数据分析，我们来写一个解析器。</p><p><br/></p><p>class PoemContentParser(HTMLParser):</p><p>    def __init__(self):</p><p>        HTMLParser.__init__(self)</p><p>        self.content = []   //把它变成一个列表</p><p>        self.in_p = False   //定义一个标志位</p><p><br/></p><p>    def handle_starttag(self, tag, attrs): </p><p>        if tag == 'p' and _attr(attrs, 'align') == 'center':   //标签等于p，而且align的属性等于center</p><p>            self.in_p = True   //这样的标签我们认为是一个合法的标签</p><p><br/></p><p>    def handle_endtag(self, tag):   //退出了p这个字段以后，我们就认为不再这个数据范围里面</p><p>        if tag == 'p':   //标志位</p><p>            self.in_p = False</p><p><br/></p><p>    def handle_data(self, data):   //处理数据</p><p>        if self.in_p:   //只要在我们的合法标签内，我们就认为是我们想要的数据</p><p>            self.content.append(data)</p><p><br/></p><p>这样我们就把诗词的内容全部给它爬下来了，因为我们爬出来的正文因为是个列表，所以我们要使用回车列表符把这个列表都给它连接起来，写法如下：</p><p><br/></p><p>def download_poem(poem):</p><p>r = requests.get('http://www.gushiwen.org' + poem['url'])   //唐诗所在的url</p><p>r = request.get(url)  //下载唐诗的网页</p><p>parser = PoemContentParser(r.content)   //构造一个解析器，把这个内容传进去</p><p>return ‘\n’.join parser.content   //返回唐诗的内容，它会返回列表里面的所有文本</p><p><br/></p><p>运行以下代码，</p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p>import re</p><p>from HTMLParser import HTMLParser</p><p><br/></p><p># ugly code to fix UnicodeDecodeError</p><p>import sys</p><p>reload(sys)</p><p>sys.setdefaultencoding('utf8')</p><p><br/></p><p><br/></p><p>def _attr(attrs, attrname):</p><p>    for attr in attrs:</p><p>        if attr[0] == attrname:</p><p>            return attr[1]</p><p>    return None</p><p><br/></p><p><br/></p><p>class PoemParser(HTMLParser):</p><p>    def __init__(self):</p><p>        HTMLParser.__init__(self)</p><p>        self.in_div = False</p><p>        self.in_a = False</p><p>        self.pattern = re.compile(r'(.*)\((.*)\)')</p><p>        self.tangshi_list = []</p><p>        self.current_poem = {}</p><p><br/></p><p>    def handle_starttag(self, tag, attrs):</p><p>        if tag == 'div' and _attr(attrs, 'class') == 'guwencont2':</p><p>            self.in_div = True</p><p><br/></p><p>        if tag == 'a' and self.in_div:</p><p>            self.in_a = True</p><p>            self.current_poem['url'] = _attr(attrs, 'href')</p><p><br/></p><p>    def handle_endtag(self, tag):</p><p>        if tag == 'div':</p><p>            self.in_div = False</p><p><br/></p><p>        if tag == 'a':</p><p>            self.in_a = False</p><p><br/></p><p>    def handle_data(self, data):</p><p>        if self.in_a:</p><p>            m = self.pattern.match(data)</p><p>            if m:</p><p>                self.current_poem['title'] = m.group(1)</p><p>                self.current_poem['author'] = m.group(2)</p><p>                self.tangshi_list.append(self.current_poem)</p><p>                self.current_poem = {}</p><p><br/></p><p>class PoemContentParser(HTMLParser):</p><p>    def __init__(self):</p><p>        HTMLParser.__init__(self)</p><p>        self.content = []   //把它变成一个列表</p><p>        self.in_p = False   //定义一个标志位</p><p><br/></p><p>    def handle_starttag(self, tag, attrs): </p><p>        if tag == 'p' and _attr(attrs, 'align') == 'center':   //标签等于p，而且align的属性等于center</p><p>            self.in_p = True   //这样的标签我们认为是一个合法的标签</p><p><br/></p><p>    def handle_endtag(self, tag):   //退出了p这个字段以后，我们就认为不再这个数据范围里面</p><p>        if tag == 'p':   //标志位</p><p>            self.in_p = False</p><p><br/></p><p>    def handle_data(self, data):   //处理数据</p><p>        if self.in_p:   //只要在我们的合法标签内，我们就认为是我们想要的数据</p><p>             self.content.append(data)</p><p><br/></p><p>def retrive_tangshi_300():</p><p>    url = 'http://www.gushiwen.org/gushi/tangshi.aspx'</p><p>    r = requests.get(url)</p><p>    parser = PoemParser()</p><p>    parser.feed(r.content)</p><p>    return parser.tangshi_list</p><p><br/></p><p>def download_poem(poem):</p><p>r = requests.get('http://www.gushiwen.org' + poem['url'])   //唐诗所在的url</p><p>r = request.get(url)  //下载唐诗的网页</p><p>parser = PoemContentParser(r.content)   //构造一个解析器，把这个内容传进去</p><p>    return ‘\n’.join parser.content   //返回唐诗的内容，它会返回列表里面的所有文本</p><p><br/></p><p>def trim_ws(s):</p><p>return s</p><p><br/></p><p>def trim_href(s):</p><p>    return trim_ws(s)</p><p><br/></p><p>def trim_test():</p><p>    s = """月落乌啼霜满天，江枫渔火对愁眠。</p><p>           姑苏城外</p><p>           寒山</p><p>           寺，夜半钟声到客船。"""</p><p>    print(trim_ws(s))</p><p><br/></p><p>    s = """</p><p>        凉风起天末，君子意如何。&lt;br&gt;</p><p>        鸿雁几时到，江湖秋水多。&lt;br&gt;</p><p>        文章憎命达，魑魅喜人过。&lt;br&gt;</p><p>        应共冤魂语，投&lt;a href="http://www.gushiwen.org/GuShiWen_148389ab4e.aspx"&gt;&lt;img style="vertical-align:middle;" src="http://www.gushiwen.org/favicon.ico" alt="诗" title="诗" width="14" height="14"&gt;&lt;/a&gt;</p><p>        赠汨罗。"""</p><p>    print(trim_href(s))</p><p><br/></p><p><br/></p><p>if __name__ == '__main__':</p><p>    l = retrive_tangshi_300()</p><p>    print('total %d poems.' % len(l))</p><p>    for i in range(10):</p><p>        print('标题: %(title)s\t作者：%(author)s\tURL: %(url)s' % (l[i]))</p><p><br/></p><p>    # download each poem</p><p>    for i in range(len(l)):</p><p>        print('#%d downloading poem from: %s' % (i, l[i]['url']))</p><p>        download_poem(l[i])</p><p>        print('标题: %(title)s\t作者：%(author)s\n%(content)s' % (l[i]))</p><p>trim_test()</p><p><br/></p><p>运行这个代码，我们可以看到这里面有报错。</p><p><br/></p><p><img alt="grab3.png" src="images/92bc28b7b7dd4f0a8e08268733302ff7.png" title="kEMIMseZ69rjbk4r4a.png"/></p><p><br/></p><p>修改代码</p><p><br/></p><p># -*- coding: utf-8 -*-</p><p>import requests</p><p>import re</p><p>from HTMLParser import HTMLParser</p><p><br/></p><p># ugly code to fix UnicodeDecodeError</p><p>import sys</p><p>reload(sys)</p><p>sys.setdefaultencoding('utf8')</p><p><br/></p><p><br/></p><p>def _attr(attrs, attrname):</p><p>    for attr in attrs:</p><p>        if attr[0] == attrname:</p><p>            return attr[1]</p><p>    return None</p><p><br/></p><p><br/></p><p>class PoemParser(HTMLParser):</p><p>    def __init__(self):</p><p>        HTMLParser.__init__(self)</p><p>        self.in_div = False</p><p>        self.in_a = False</p><p>        self.pattern = re.compile(r'(.*)\((.*)\)')</p><p>        self.tangshi_list = []</p><p>        self.current_poem = {}</p><p><br/></p><p>    def handle_starttag(self, tag, attrs):</p><p>        if tag == 'div' and _attr(attrs, 'class') == 'guwencont2':</p><p>            self.in_div = True</p><p><br/></p><p>        if tag == 'a' and self.in_div:</p><p>            self.in_a = True</p><p>            self.current_poem['url'] = _attr(attrs, 'href')</p><p><br/></p><p>    def handle_endtag(self, tag):</p><p>        if tag == 'div':</p><p>            self.in_div = False</p><p><br/></p><p>        if tag == 'a':</p><p>            self.in_a = False</p><p><br/></p><p>    def handle_data(self, data):</p><p>        if self.in_a:</p><p>            m = self.pattern.match(data)</p><p>            if m:</p><p>                self.current_poem['title'] = m.group(1)</p><p>                self.current_poem['author'] = m.group(2)</p><p>                self.tangshi_list.append(self.current_poem)</p><p>                self.current_poem = {}</p><p><br/></p><p>class PoemContentParser(HTMLParser):</p><p>    def __init__(self):</p><p>        HTMLParser.__init__(self)</p><p>        self.content = []   //把它变成一个列表</p><p>        self.in_p = False   //定义一个标志位</p><p><br/></p><p>    def handle_starttag(self, tag, attrs): </p><p>        if tag == 'p' and _attr(attrs, 'align') == 'center':   //标签等于p，而且align的属性等于center</p><p>            self.in_p = True   //这样的标签我们认为是一个合法的标签</p><p><br/></p><p>    def handle_endtag(self, tag):   //退出了p这个字段以后，我们就认为不再这个数据范围里面</p><p>        if tag == 'p':   //标志位</p><p>            self.in_p = False</p><p><br/></p><p>    def handle_data(self, data):   //处理数据</p><p>        if self.in_p:   //只要在我们的合法标签内，我们就认为是我们想要的数据</p><p>             self.content.append(data)</p><p><br/></p><p>def retrive_tangshi_300():</p><p>    url = 'http://www.gushiwen.org/gushi/tangshi.aspx'</p><p>    r = requests.get(url)</p><p>    parser = PoemParser()</p><p>    parser.feed(r.content)</p><p>    return parser.tangshi_list</p><p><br/></p><p>def download_poem(poem):</p><p>    r = requests.get('http://www.gushiwen.org' + poem['url'])</p><p>    parser = PoemContentParser()</p><p>    parser.feed(r.content)</p><p>poem['content'] = '\n'.join(parser.content)   //把这个值放在字典里面</p><p><br/></p><p>def trim_ws(s):</p><p>return s</p><p><br/></p><p>def trim_href(s):</p><p>    return trim_ws(s)</p><p><br/></p><p>def trim_test():</p><p>    s = """月落乌啼霜满天，江枫渔火对愁眠。</p><p>           姑苏城外</p><p>           寒山</p><p>           寺，夜半钟声到客船。"""</p><p>    print(trim_ws(s))</p><p><br/></p><p>    s = """</p><p>        凉风起天末，君子意如何。&lt;br&gt;</p><p>        鸿雁几时到，江湖秋水多。&lt;br&gt;</p><p>        文章憎命达，魑魅喜人过。&lt;br&gt;</p><p>        应共冤魂语，投&lt;a href="http://www.gushiwen.org/GuShiWen_148389ab4e.aspx"&gt;&lt;img style="vertical-align:middle;" src="http://www.gushiwen.org/favicon.ico" alt="诗" title="诗" width="14" height="14"&gt;&lt;/a&gt;</p><p>        赠汨罗。"""</p><p>    print(trim_href(s))</p><p><br/></p><p><br/></p><p>if __name__ == '__main__':</p><p>    l = retrive_tangshi_300()</p><p>    print('total %d poems.' % len(l))</p><p>    for i in range(10):</p><p>        print('标题: %(title)s\t作者：%(author)s\tURL: %(url)s' % (l[i]))</p><p><br/></p><p>    # download each poem</p><p>    for i in range(len(l)):</p><p>        print('#%d downloading poem from: %s' % (i, l[i]['url']))</p><p>        download_poem(l[i])</p><p>        print('标题: %(title)s\t作者：%(author)s\n%(content)s' % (l[i]))</p><p>trim_test()</p><p><br/></p><p>运行结果，大家可以看到正在下载。</p><p><br/></p><p><img alt="grab4.png" src="images/f8683177e35b8e02a1f8757738c14079.png" title="ltzwmvzGcGpWZvNzRw.png"/></p><p><br/></p><p>下载完成后，总共320首，这个log会很长，我们把这个log放到另一个文件里面去分析。</p><p><br/></p><p><img alt="grab5.png" src="images/4952dc2d7dd05e089607571546446866.png" title="cmmMACbTksgvFAPuTh.png"/></p><p><br/></p><p>这些内容时我们前面打出来的前10首的标题，作者</p><p><br/></p><p><img alt="grab6.png" src="images/06f5d83a2a224ce4022fbd5e2731b440.png" title="EWcY49CAxFmMpudqHu.png"/></p><p><br/></p><p>#0开始是我们真正去下载唐诗的log，真正爬出来的是这个正文。</p><p><br/></p><p><img alt="grab7.png" src="images/551e468facf7835ec4fe1031586b881c.png" title="w2EsJgjPrhPGGNayZi.png"/></p><p><br/></p><p>这样是不是就完成了所有的内容呢？答案是不是，因为我们在写一个爬虫的时候，我们通过这个网页的规则去规划数据的时候，往往会规则不全，也就是说你可能覆盖了99%的情况，但是1%我们没有分析到，这样就导致爬出来的数据是不全的，所以这里面没有什么技巧，只能一个一个去检查，要去检查是不是数据有不正常的情况，然后通过不正常的诗词去反推我们的规则，去完善我们的规则。</p><p><br/></p><p>那我们来看看有什么不正常的数据，这里面就有一个。</p><p><br/></p><p><img alt="grab8.png" src="images/b321060cb9eb81f0dbd36000fe0a0c1c.png" title="gRjtkJ2nHk46QhDbkZ.png"/></p><p><br/></p><p>我们来看另外一个不正常的，这里面少了一个字，只有4个字。</p><p><br/></p><p><img alt="grab9.png" src="images/e29a82dfa7c828d547c03c47665d7ca1.png" title="yDb1FGNLqkQPAeeySx.png"/></p><p><br/></p><p>我们来看看为什么这个不正常呢？原来这个网站有个特色，它把诗这个字转换成了一个图片</p><p><br/></p><p><img alt="grab10.png" src="images/1823d828322f451756fdcfcb4c3291d4.png" title="Eu8LA5kZZByIjUtIC3.png"/></p><p><br/></p><p>它把它换成了一个image标签，所以就用图片来替换它，所以导致这个数据就不正常了。</p><p><br/></p><p><img alt="grab11.png" src="images/287a202720e9b853eb979194a5368a50.png" title="piH3c5jchy9a2NYFYz.png"/></p><p><br/></p><p>我们这样一个个分析下来，我们一共会分析出三个不正常的数据，这些诗是异常回车的，就是回车换行不正常。</p><p><br/></p><p><br/></p><p><span style="color: rgb(192, 0, 0);">【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></p><p><br/></p><p>
</p></p></div>
        </body></html>