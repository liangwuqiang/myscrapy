<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>深入理解爬虫原理</h1></center></p>
            <div class="cont">
<h1>深入理解爬虫原理</h1>
<p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">组成部分介绍</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><strong>1、Scrapy Engine：</strong></p><p><strong><br/></strong></p><p>负责组件之间数据的流转，当某个动作发生时触发事件；</p><p> </p><p><strong>2、Scheduler：</strong></p><p><strong><br/></strong></p><p>接收requests，并把他们入队，以便后续的调度；</p><p> </p><p><strong>3、Downloader：</strong></p><p><strong><br/></strong></p><p>负责抓取网页，并传送给引擎，之后抓取结果将传给spider；</p><p> </p><p><strong>4、Spiders：</strong></p><p><strong><br/></strong></p><p>用户编写的可定制化的部分，负责解析response，产生items和URL；</p><p> </p><p><strong>5、Item Pipeline：</strong></p><p><br/></p><p>负责处理item，典型的用途：清洗、验证、持久化；</p><p> </p><p><strong>6、Downloader middlewares：</strong></p><p><br/></p><p>位于引擎和下载器之间的一个钩子，处理传送到下载器的requests和传送到引擎的response；</p><p> </p><p><strong>7、Spider middlewares：</strong></p><p><br/></p><p>位于引擎和抓取器之间的一个钩子，处理抓取器的输入和输出。</p><p><br/></p><p><img alt="Python1.png" src="images/c5380178d2c8722eb6fd880307784584.png" title="i8qmw3Rr9us6G6ZxkY.png"/> </p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">数据流通介绍</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p>Scrapy中的数据流由执行引擎控制，其过程如下:</p><p><br/></p><p>1、引擎打开一个网站(open a domain)，找到处理该网站的Spider并向该spider请求第一个要爬取的URL(s)。</p><p>2、引擎从Spider中获取到第一个要爬取的URL并在调度器(Scheduler)以Request调度。</p><p>3、引擎向调度器请求下一个要爬取的URL。 </p><p>4、调度器返回下一个要爬取的URL给引擎，引擎将URL通过下载中间件(请求(request)方向)转发给下载器(Downloader)。 </p><p>5、一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(返回(response)方向)发送给引擎。 </p><p>6、引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理。 </p><p>7、Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎。 </p><p>8、引擎将(Spider返回的)爬取到的Item给Item Pipeline，将(Spider返回的)Request给调度器。 </p><p>9、(从第二步)重复直到调度器中没有更多地request，引擎关闭该网站。</p><p> </p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">中间件的编写</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><strong>1、down loader middle ware</strong></p><p><strong><br/></strong></p><p>Each middleware component is a Python class that defines one or more of the following methods: </p><p>class scrapy.downloadermiddlewares.DownloaderMiddleware</p><p>process_request(request, spider)</p><p>This method is called for each request that goes through the download middleware.</p><p>process_request() should either: return None, return a Response object, return a Request object, or raise IgnoreRequest.</p><p>If it returns None, Scrapy will continue processing this request, executing all other middlewares until, finally, the appropriate downloader handler is called the request performed (and its response downloaded).</p><p>If it returns a Response object, Scrapy won’t bother calling any other process_request() or process_exception() methods, or the appropriate download function; it’ll return that response. The process_response() methods of installed middleware is always called on every response. </p><p>If it returns a Request object, Scrapy will stop calling process_request methods and reschedule the returned request. Once the newly returned request is performed, the appropriate middleware chain will be called on the downloaded response. </p><p>If it raises an IgnoreRequest exception, the process_exception() methods of installed down-loader middleware will be called. If none of them handle the exception, the errback function of the request (Request.errback) is called. If no code handles the raised exception, it is ignored and not logged (unlike other exceptions).</p><p> </p><p>Parameters</p><p>• request (Request object) – the request being processed </p><p>• spider (Spider object) – the spider for which this request is intended</p><p>process_response(request, response, spider)</p><p>process_response() should either: return a Response object, return a Request object or raise a</p><p>IgnoreRequest exception.</p><p>If it returns a Response (it could be the same given response, or a brand-new one), that response will continue to be processed with the process_response() of the next middleware in the chain.</p><p>If it returns a Request object, the middleware chain is halted and the returned request is resched-uled to be downloaded in the future. This is the same behavior as if a request is returned from process_request(). </p><p>If it raises an IgnoreRequest exception, the errback function of the request (Request.errback) is called. If no code handles the raised exception, it is ignored and not logged (unlike other exceptions).</p><p><br/></p><p>Parameters</p><p>• request (is a Request object) – the request that originated the response</p><p>• response (Response object) – the response being processed</p><p>• spider (Spider object) – the spider for which this response is intended</p><p>process_exception(request, exception, spider) </p><p>Scrapy calls process_exception() when a download handler or a process_request() (from a downloader middleware) raises an exception (including an IgnoreRequest exception) </p><p>process_exception() should return: either None, a Response object, or a Request object. </p><p>If it returns None, Scrapy will continue processing this exception, executing any other process_exception() methods of installed middleware, until no middleware is left and the default exception handling kicks in.</p><p>If it returns a Response object, the process_response() method chain of installed middleware is started, and Scrapy won’t bother calling any other process_exception() methods of middleware.</p><p>If it returns a Request object, the returned request is rescheduled to be downloaded in the future. This stops the execution of process_exception() methods of the middleware the same as returning a response would.</p><p><br/></p><p>Parameters</p><p>request (is a Request object) – the request that generated the exception </p><p>exception (an Exception object) – the raised exception</p><p>spider (Spider object) – the spider for which this request is intended</p><p><br/></p><p><strong>2、spider middle wares</strong><span style=";font-family:宋体;font-size:16px"> </span></p><p><strong><span style=";font-family:宋体;font-size:16px"><br/></span></strong></p><p>Each middleware component is a Python class that defines one or more of the following methods:</p><p>class scrapy.spidermiddlewares.SpiderMiddleware</p><p>process_spider_input(response, spider)</p><p>This method is called for each response that goes through the spider middleware and into the spider, for processing.</p><p>process_spider_input() should return None or raise an exception.</p><p>If it returns None, Scrapy will continue processing this response, executing all other middlewares until, finally, the response is handed to the spider for processing. </p><p>If it raises an exception, Scrapy won’t bother calling any other spider middleware process_spider_input() and will call the request errback. The output of the errback is chained back in the other direction for process_spider_output() to process it, or process_spider_exception() if it raised an exception.</p><p><br/></p><p>Parameters </p><p>• response (Response object) – the response being processed</p><p>• spider (Spider object) – the spider for which this response is intended</p><p>process_spider_output(response, result, spider) </p><p>This method is called with the results returned from the Spider, after it has processed the response. </p><p>process_spider_output() must return an iterable of Request, dict or Item objects. </p><p><br/></p><p>Parameters </p><p>• response (Response object) – the response which generated this output from the spi-der </p><p>• result (an iterable of Request, dict or Item objects) – the result returned by the spider </p><p>• spider (Spider object) – the spider whose result is being processed</p><p> </p><p>process_spider_exception(response, exception, spider) </p><p>This method is called when when a spider or process_spider_input() method (from other spider middleware) raises an exception. </p><p>process_spider_exception() should return either None or an iterable of Response, dict or Item objects. </p><p>If it returns None, Scrapy will continue processing this exception, executing any other process_spider_exception() in the following middleware components, until no middleware components are left and the exception reaches the engine (where it’s logged and discarded).</p><p>If it returns an iterable the process_spider_output() pipeline kicks in, and no other process_spider_exception() will be called.</p><p> </p><p>Parameters </p><p>• response (Response object) – the response being processed when the exception was raised </p><p>• exception (Exception object) – the exception raised </p><p>• spider (Spider object) – the spider which raised the exception</p><p> </p><p>process_start_requests(start_requests, spider)</p><p>New in version 0.15. </p><p>This method is called with the start requests of the spider, and works similarly to the process_spider_output() method, except that it doesn’t have a response associated and must return only requests (not items). </p><p>It receives an iterable (in the start_requests parameter) and must return another iterable of Request objects.</p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">查看以前的spider内容</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><img alt="Python2.png" src="images/2ed6b1844db1cc2f94893a9a5ac98c26.png" title="QdQ7c2bCaOeOcr86yW.png"/> </p><p><br/></p><p><img alt="Python3.png" height="228" src="images/67148dba50da7f8b6cee01eefab63959.png" style="width: 597px; height: 228px;" title="dJzhPxaWSN99S1WVti.png" width="597"/> </p><p><br/></p><p><img alt="Python4.png" height="140" src="images/44c09531e1bd6421d5dc41db2d3be2c4.png" style="width: 601px; height: 140px;" title="S8WxpX28ERFoLG71Pm.png" width="601"/><span style=";font-family:Calibri;font-size:14px"> </span></p><p><span style=";font-family:Calibri;font-size:14px"> </span></p><p><br/></p><p><span style='color: rgb(192, 0, 0); font-family: "microsoft yahei"; font-weight: bold; line-height: 20px; background-color: rgb(255, 255, 255);'>【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></p><p>
</p></p></div>
        </body></html>