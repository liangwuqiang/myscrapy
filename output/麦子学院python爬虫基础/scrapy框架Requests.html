<!DOCTYPE html>
        <html><head><meta charset="UTF-8">
        </head><body>
        <p><center><h1>scrapy框架Requests</h1></center></p>
            <div class="cont">
<h1>scrapy框架Requests</h1>
<p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">初始化参数</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p>class scrapy.http.Request(</p><p>url [ , </p><p>callback, </p><p>method='GET',</p><p>headers, </p><p>body,</p><p>cookies, </p><p>meta,</p><p>encoding='utf-8',  </p><p>priority=0,</p><p> don't_filter=False,</p><p> errback ] )</p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">其他属性</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><strong>url</strong></p><p><strong><br/></strong></p><p>A string containing the URL of this request. Keep in mind that this attribute contains the escaped URL, so it can differ from the URL passed in the constructor.</p><p>This attribute is read-only. To change the URL of a Request use replace().</p><p><br/></p><p><strong>method</strong></p><p> </p><p>A string representing the HTTP method in the request. This is guaranteed to be uppercase. Example:</p><p>"GET", "POST", "PUT", etc</p><p><br/></p><p><strong>headers</strong></p><p><strong><br/></strong></p><p>A dictionary-like object which contains the request headers.</p><p><br/></p><p><strong>body</strong></p><p><strong><br/></strong></p><p>A str that contains the request body.</p><p>This attribute is read-only. To change the body of a Request use replace().</p><p><br/></p><p><strong>meta</strong></p><p><strong><br/></strong></p><p>A dict that contains arbitrary metadata for this request. This dict is empty for new Requests, and is usually populated by different Scrapy components (extensions, middlewares, etc). So the data contained in this dict depends on the extensions you have enabled.</p><p>See Request.meta special keys for a list of special meta keys recognized by Scrapy.</p><p>This dict is shallow copied when the request is cloned using the copy() or replace() methods, and can also be accessed, in your spider, from the response.meta attribute.</p><p><br/></p><p><strong>copy()</strong></p><p><strong><br/></strong></p><p>Return a new Request which is a copy of this Request. See also: Passing additional data to callback functions.</p><p> </p><p><strong>replace</strong></p><p><strong><br/></strong></p><p>([url, method, headers, body, cookies, meta, encoding, dont_filter, callback, errback ])</p><p>Return a Request object with the same members, except for those members given new values by whichever keyword arguments are specified. The attribute Request.meta is copied by default (unless a new value is given in the meta argument). See also Passing additional data to callback functions.</p><p><br/></p><h3><span style="color: rgb(94, 207, 186);"></span></h3><hr/><h3><span style="color: rgb(94, 207, 186);">实例</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p>1）生成Request的方法；</p><p>2）通过Request传递数据的方法；</p><p>3）Request.meta中的特殊关键字；</p><p><br/></p><p><strong>例1：</strong></p><p><strong><br/></strong></p><p>def parse_page1(self, response):</p><p>return scrapy.Request("http://www.example.com/some_page.html", callback=self.parse_page2) </p><p>def parse_page2(self, response):</p><p># this would log http://www.example.com/some_page.html self.logger.info("Visited %s", response.url)</p><p><strong><br/></strong></p><p><strong>例2：</strong></p><p><strong><br/></strong></p><p>def parse_page1(self, response):</p><p>item = MyItem()</p><p>item['main_url'] = response.url</p><p>request = scrapy.Request("http://www.example.com/some_page.html", callback=self.parse_page2)</p><p>request.meta['item'] = item return request</p><p>item = response.meta['item']</p><p>item['other_url'] = response.url</p><p>return item</p><p>def parse_page2(self, response):</p><p><br/></p><hr/><p><br/></p><h3><span style="color: rgb(94, 207, 186);">子类介绍</span><br/></h3><p><span style="color: rgb(94, 207, 186);"><br/></span></p><p><strong>FormRequest:</strong></p><p><strong><br/></strong></p><p>1,new parameter: formdata</p><p>2,new class method method: from_reponse</p><p> </p><p>The FormRequest class extends the base Request with functionality for dealing with HTML forms. It uses lxml.html forms to pre-populate form fields with form data from Response objects.</p><p>class scrapy.http.FormRequest(url[, formdata, ... ])</p><p>The FormRequest class adds a new argument to the constructor. The remaining arguments are the same as for the Request class and are not documented here.</p><p><strong><br/></strong></p><p><strong>例1：</strong></p><p><strong><br/></strong></p><p>return [FormRequest(url="http://www.example.com/post/action", formdata={'name': 'John Doe', 'age': '27'}, callback=self.after_post)]</p><p><strong><br/></strong></p><p><strong>例2：</strong></p><p><strong><br/></strong></p><p>import scrapy</p><p>class LoginSpider(scrapy.Spider): name = 'example.com'</p><p>start_urls = ['http://www.example.com/users/login.php'] </p><p>def parse(self, response):</p><p>return scrapy.FormRequest.from_response( response,</p><p>formdata={'username': 'john', 'password': 'secret'}, callback=self.after_login </p><p>)</p><p>def after_login(self, response): </p><p># check login succeed before going on </p><p>if "authentication failed" in response.body: self.logger.error("Login failed") </p><p>return</p><p><br/></p><p><br/></p><p><span style='color: rgb(192, 0, 0); font-family: "microsoft yahei"; font-weight: bold; line-height: 20px; background-color: rgb(255, 255, 255);'>【本文由麦子学院独家原创，转载请注明出处并保留原文链接】</span></p><p>
</p></p></div>
        </body></html>